{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "model = keras.models.load_model(r\"C:\\Users\\hp\\Desktop\\Career Excellence Maam\\Face Recognition\\FaceRecognitionMV.model\")\n",
    "CATEGORIES = [\"Mayank\", \"Vanshika\"]\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "gender_list = ['Male', 'Female']\n",
    "age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')\n",
    "gender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = video_capture.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "profileface = \"haarcascade_profileface.xml\"\n",
    "frontalface = \"haarcascade_frontalface_default.xml\"\n",
    "profilefacecascade = cv2.CascadeClassifier(profileface)\n",
    "frontalfacecascade = cv2.CascadeClassifier(frontalface)\n",
    "#video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = frontalfacecascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize=(20, 20),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        if len(faces) == 0:\n",
    "            faces = profilefacecascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.2,\n",
    "                minNeighbors=5,\n",
    "                minSize=(20, 20),\n",
    "                flags=cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "        if len(faces) == 0:\n",
    "            faces = profilefacecascade.detectMultiScale(\n",
    "            cv2.flip(gray ,1),\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(20, 20),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "            frame = cv2.flip(frame,1)\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 3)\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                roi_color = frame[y:y+h, x:x+w]\n",
    "                #cv2.imwrite(\"Dataset/User.\"+str(face_id)+'.'+str(count)+\".jpg\",cv2.flip(roi_gray,1))\n",
    "            frame = cv2.flip(frame,1)\n",
    "        else:\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 3)\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                roi_color = frame[y:y+h, x:x+w]\n",
    "                #cv2.imwrite(r\"C:\\Users\\hp\\Desktop\\Career Excellence Maam\\Face Recognition\\Testing\\Mk.jpg\",roi_gray)\n",
    "        target = cv2.resize(roi_gray, (128, 128))\n",
    "        target = target.reshape(1, 128, 128,1)\n",
    "        target = np.array(target,dtype='float32')/255\n",
    "        p=model.predict(target)\n",
    "        sol=(CATEGORIES[np.argmax(p)])\n",
    "        \n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(roi_color, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        gender_net.setInput(blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        gender = gender_list[gender_preds[0].argmax()]\n",
    "        age_net.setInput(blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age = age_list[age_preds[0].argmax()]\n",
    "        overlay_text = \"%s %s %s\" % (sol,gender, age)\n",
    "        cv2.putText(frame, overlay_text, (300,300), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('Video', frame)\n",
    "        \n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
